{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c657c9b1",
      "metadata": {
        "id": "c657c9b1"
      },
      "source": [
        "### Binary semantic segmentation example using U-Net\n",
        "\n",
        "https://github.com/bnsreenu/python_for_image_processing_APEER/blob/master/tutorial118_binary_semantic_segmentation_using_unet.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a8e8a9f6",
      "metadata": {
        "id": "a8e8a9f6"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore tensorflow warnings\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' # allow GPU memory growth\n",
        "\n",
        "import glob\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())\n",
        "print('\\n')\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "id": "Ps23eD3RQA1q",
        "outputId": "5d8e2e76-16e7-40a0-9b51-4c8ff7bb513e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ps23eD3RQA1q",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n",
            "\n",
            "\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 16953317165348376971\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14417788928\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 2318304816283472259\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "i8HIq9kwLuy6",
        "outputId": "7b5ae329-8b2a-4bcc-99eb-952c15a17e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i8HIq9kwLuy6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset --> run only in Colab\n",
        "import zipfile\n",
        "\n",
        "mapai_zip = '/content/drive/MyDrive/prekmurje/prekmurje.zip'\n",
        "zip_ref = zipfile.ZipFile(mapai_zip, 'r')\n",
        "zip_ref.extractall(\"/tmp\") # extracting dataset to tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "3FcP1IjpLpcr"
      },
      "id": "3FcP1IjpLpcr",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-run from here after first run! "
      ],
      "metadata": {
        "id": "mGuQ7uygOB4b"
      },
      "id": "mGuQ7uygOB4b"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a78c221",
      "metadata": {
        "id": "0a78c221"
      },
      "outputs": [],
      "source": [
        "# Configure paths\n",
        "\n",
        "img_dir = '/tmp/prekmurje/train/images'\n",
        "mask_dir = '/tmp/prekmurje/train/masks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f0c0f468",
      "metadata": {
        "id": "f0c0f468"
      },
      "outputs": [],
      "source": [
        "SIZE = 128\n",
        "num_images = 46440"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b62c047",
      "metadata": {
        "id": "5b62c047"
      },
      "source": [
        "#### Load images and masks in order so they match."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b114a83b",
      "metadata": {
        "id": "b114a83b"
      },
      "source": [
        "#### IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c7ab864e",
      "metadata": {
        "id": "c7ab864e",
        "outputId": "832665fd-d6d2-4c33-a531-48d3a07470c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46440\n"
          ]
        }
      ],
      "source": [
        "image_names = glob.glob('/tmp/prekmurje/train/images/*.png')\n",
        "\n",
        "# Create subset\n",
        "image_names_subset = image_names[0:num_images]\n",
        "# Read each subset with cv2\n",
        "images = [cv2.imread(img, 0) for img in image_names_subset]\n",
        "# Create dataset\n",
        "image_dataset = np.array(images)\n",
        "image_dataset = np.expand_dims(image_dataset, axis = 3)\n",
        "\n",
        "print(len(image_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f71a4ac",
      "metadata": {
        "id": "7f71a4ac"
      },
      "source": [
        "#### MASKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fa17c5fc",
      "metadata": {
        "id": "fa17c5fc",
        "outputId": "b63a988c-cfa8-44b7-b9d1-ed42b08944a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46440\n"
          ]
        }
      ],
      "source": [
        "mask_names = glob.glob('/tmp/prekmurje/train/masks/*.png')\n",
        "mask_names.sort()\n",
        "mask_names_subset = mask_names[0:num_images]\n",
        "masks = [cv2.imread(mask, 0) for mask in mask_names_subset]\n",
        "mask_dataset = np.array(masks)\n",
        "mask_dataset = np.expand_dims(mask_dataset, axis = 3)\n",
        "\n",
        "print(len(mask_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c8cdea",
      "metadata": {
        "id": "43c8cdea"
      },
      "source": [
        "#### Print properties of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "02cc1ff9",
      "metadata": {
        "id": "02cc1ff9",
        "outputId": "a6365b2e-959d-4b1e-d842-1da928219824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image data shape is:  (46440, 128, 128, 1)\n",
            "Mask data shape is:  (46440, 128, 128, 1)\n",
            "Max pixel value in image is:  253\n",
            "Labels in the mask are :  [  0 255]\n"
          ]
        }
      ],
      "source": [
        "print(\"Image data shape is: \", image_dataset.shape)\n",
        "print(\"Mask data shape is: \", mask_dataset.shape)\n",
        "print(\"Max pixel value in image is: \", image_dataset.max())\n",
        "print(\"Labels in the mask are : \", np.unique(mask_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f672d14",
      "metadata": {
        "id": "9f672d14"
      },
      "source": [
        "#### Normalize images\n",
        "Getting OOM errors, maybe need to find a better way to normalize images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "06394c42",
      "metadata": {
        "id": "06394c42"
      },
      "outputs": [],
      "source": [
        "# IMAGES\n",
        "# Solution: https://stackoverflow.com/questions/62977311/how-can-i-stop-my-colab-notebook-from-crashing-while-normalising-my-images\n",
        "\n",
        "image_dataset = (image_dataset / 255.0).astype(np.float16)  #Can also normalize or scale using MinMax scaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to figure out a way to lower system RAM after normalization\n",
        "type(mask_dataset)"
      ],
      "metadata": {
        "id": "6nIuATPKPYvB",
        "outputId": "80ead5a5-4772-4a46-8c77-a646178e88c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6nIuATPKPYvB",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MASKS\n",
        "\n",
        "#Do not normalize masks, just rescale to 0 to 1.\n",
        "mask_dataset = (mask_dataset / 255.0).astype(np.float16)   #PIxel values will be 0 or 1"
      ],
      "metadata": {
        "id": "kHX9z7r5OmaL"
      },
      "id": "kHX9z7r5OmaL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679b4a0d",
      "metadata": {
        "id": "679b4a0d"
      },
      "outputs": [],
      "source": [
        "# \n",
        "print(len(image_dataset), len(mask_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b78112",
      "metadata": {
        "id": "63b78112"
      },
      "source": [
        "#### Perform train/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69916a23",
      "metadata": {
        "id": "69916a23"
      },
      "outputs": [],
      "source": [
        "# kernel dies\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ca990f",
      "metadata": {
        "id": "d2ca990f"
      },
      "source": [
        "#### Randomly view some images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d1c7a6",
      "metadata": {
        "id": "87d1c7a6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "image_number = random.randint(0, len(X_train)-1)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[image_number,:,:,0], cmap='gray')\n",
        "plt.subplot(122)\n",
        "plt.imshow(y_train[image_number,:,:,0], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a46860",
      "metadata": {
        "id": "30a46860"
      },
      "source": [
        "### U-Net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5601e44",
      "metadata": {
        "id": "e5601e44"
      },
      "outputs": [],
      "source": [
        "# Building Unet by dividing encoder and decoder into blocks\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape, n_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    if n_classes == 1:  #Binary\n",
        "      activation = 'sigmoid'\n",
        "    else:\n",
        "      activation = 'softmax'\n",
        "\n",
        "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(activation)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}